---
title: "Data Wrangling with R"
author: 'Lutao DAI'
date: "Aug 20, 2019"
output:
  rmdformats::readthedown:
    self_contained: true
    thumbnails: true
    lightbox: true
    gallery: false
    highlight: tango
  html_document:
    code_folding: show
    highlight: haddock
    theme: lumen #yeti #spacelab #simplex #readable #paper #flatly #cosmo #lumen
    toc: yes
    toc_depth: 3
    toc_float: yes
  pdf_document:
    toc: yes
    toc_depth: 4
---

```{r, include=F}
require(pacman)
pacman::p_load(tidyverse, Ecdat, kableExtra, nycflights13)
```


# Datasets
## World Happiness Report 2018 Dataset


Column Name                  | Explaination                                
:---------------------------:|:----------------------------------------
Rank                         | Overall happiness ranking
Country                      | Country name
Score                        | Happiness score
GDP_Per_Capita               | Economic contribution to happiness score
Social_Support               | Social contribution to happiness score
Healthy_Life_Expectancy      | Health contribution to happiness score
Freedom_To_Make_Life_Choices | Freedom contribution to happiness score
Generosity                   | Generosity contribution to happiness score
Perceptions_Of_Corruption    | Trustworthiness contribution to happiness score
Residual                     | Portion of happiness score that is not attributed to any of the listed categories

`vec.len` indicates how many ‘first few’ elements are displayed of each vector. You can leave it to the default value. I have set this argument to 1 for better output file formating.

```{r}
happy.df <- read.csv("../data/WorldHappiness2018_Data.csv")
str(happy.df, vec.len=1)
```

Reference:

1. https://www.kaggle.com/PromptCloudHQ/world-happiness-report-2019
1. https://worldhappiness.report/ed/2019/

## Wages and Education of Young Males Datasets

Column Name   | Explaination                                
:------------:|:----------------------------------------
nr            | Identifier
year          | Year
school        | Years of schooling
exper         | Years of experience ($=$age$-6-$school)
union         | If wage is set by collective bargaining
ethn          | Ethnicity
maried        | If married
health        | If he has health problems
wage          | Log hourly wage
industry     | Industry that he was in
occupation    | Occupation
residence    | Residence location

```{r}
str(Males, vec.len=1)
```

## NYC Flights Data in 2013
A data frame contains all 336,776 flights departing from New York City in 2013.

Column Name                   | Explaination                                                                           
:----------------------------:|:------------------------------------------------------------------------
year, month, day              | Date of departure
dep_time, arr_time            | Actual departure and arrival times (format HHMM or HMM), local tz.
sched_dep_time, sched_arr_time| Scheduled departure and arrival times (format HHMM or HMM), local tz.
dep_delay,arr_delay           |Departure and arrival delays, in minutes. Negative times represent early departures/arrivals.
hour, minute                  | Time of scheduled departure broken into hour and minutes.
carrier                       | Two letter carrier abbreviation. See airlines() to get name
tailnum                       | Plane tail number
flight                        | Flight number
origin, dest                  | Origin and destination. See airports() for additional metadata.
air_time                      | Amount of time spent in the air, in minutes
distance                      | Distance between airports, in miles
time_hour                     | Scheduled date and hour of the flight as a POSIXct date. Along with origin, can be used to join flights data to weather data.


```{r}
str(flights)
```

```{r, include=FALSE}
happy.df <- as_data_frame(happy.df)
Males <- as_data_frame(Males)
```


# dplyr: Data Transformation
## filter()
> `filter()` allows you to subset rows based on criterions related to their values

Operations that can be used to set up criterions include:

1. comparisons: `>`, `>=`, `<`, `<=`, `==` (equal), `!=` (not equal)
1. logical operators: `&` (and), `|` (or). Don't use `&&` or `||`.
1. `%in%` operator.


`dplyr` functions can be used both with and without pipe (`%>%`). When used without pipe, the first argument to the function is the dataframe. For example, to subset all observations recorded in the year 1980:
```{r}
filter(Males, year == 1980)
```

However, you are encouraged to call dplyr functions with pipe, because it outlines the sequences of how a dataframe is processed, therefore, more clear logically.

Simply put, the following two expressions are identical:
```r
# expression 1
x %>% 
  function(y)
  
# expression 2
function(x, y)
```

> Pipe symbol `%>%` takes whatever returns from the previous step as the first argument of the subsequent function.

In the context of applying dplyr functions, the following formula comes in handy.
```r
> data.frame %>% 
>   function1(arguments) %>% 
>   function2(arguments) %>% 
> ...
```

For example, to subset observations in the year 1980 with pipe:

```{r}
Males %>% 
  filter(year == 1980)
```


`filter()` accepts multiple conditions seperated by commas. 

> Multiple conditions are treated as and (`&`) logically. 

To subset hispanic observations in the year 1980:
```{r}
Males %>% 
  filter(year == 1980, ethn == "hisp")
```

> Other logical relationships should be explicitly specified. 

For example:
```{r}
Males %>% 
  filter(year == 1980 | maried == "no")
```

Finally, let's look at an example of `%in%`. `%in%` is equivalent to "is an instance of" in statistics. For example, if $x$ is an instance of the set $X$, then `x %in% X` will return `TRUE`.

To subset observations from year 1980 to 1983 (both inclusive):
```{r}
Males %>% 
  filter(year %in% 1980:1983)
```

> `filter()` excludes `NA` for you

```{r}
data.frame(x = c(1, NA, NA, 4)) %>% 
  filter(x > 1)
```



## arrange()
> `arrange()` changes the order of rows. Usually, it is used to sort observations in ascending (by default) or descending order (with `desc()`).

The argument to `arrange()` is simply the column names. By default, the observations will be organized in ascending order. If multiple columns are passed, latter columns will only have effect for those observations that share the value of ALL preceding columns. 

For example, observations are first sorted by `year` in ascending order, so observations in the year 1980 come to the front. For observations occur in the same year, their order is further determined by the value in the column `school`:
```{r}
Males %>% 
  arrange(year, school)
```

To sort observations in descending order, pass the column to function `desc()` first.
```{r}
happy.df %>% 
  arrange(desc(Rank))
```

> Missing values are always sorted at the end, regardless of ascending or descending order.

```{r}
df <- tibble(x = c(15, NA, 22, NA, -43, NA))
df %>% 
  arrange(x)
```

```{r}
df %>% 
  arrange(desc(x))
```

How to sort all missing values to the start?
```{r}
df %>% 
  arrange(desc(is.na(x)), x)
```

## select()
It is not uncommon for the number of columns to reach hundreds or even thousands level. Under this circumstances, it is helpful to single out a few more important columns and examine them first. 

> `select()` is use to subset columns from a dataframe.

`select()` is similar to `filter()` for rows.

The dataframe `Males` contain 12 columns. Suppose we are only concerned with 4 of them: `school`, `maried`, `health` and `wage`. To create a sub-dataframe with only those four columns:
```{r}
Males %>% 
  select(school, maried, health, wage)
```

> You can use `:` to select all the columns continuously

Suppose we would like to select all columns between `year` and `wage`:
```{r}
Males %>% 
  select(year:wage)
```

> You can put the negative sign `-` in front of column names to exclude those columns

This works for a single columns, a vector, or a sequence specified by `:`
```{r}
Males %>% 
  select(-c(year, union))
```

### Handy helper functions that can be used in `select()`
1. `starts_with("str")`
1. `ends_with("str")`
1. `contains("str")`
1. `one_of()` #matches variable names in a character vector
1. `everything()` #matches all variables
1. `matches("(.)\\1")` #matches a regular expression
1. `num_range("x", 1:3)` #matches x1, x2 and x3
1. `last_col(offset=0)` #select last $n$ column, specified by `offset=`



```{r}
happy.df %>% 
  select(starts_with("G"))
```



> Special function `everything()` can be used to put the most important columns to the front.

```{r}
Males %>% 
  select(wage, school, everything())
```

In this scenario, does `everything()` include `wage`?

## rename()
> `rename()` is used to rename the name of columns. The syntax is `rename(new_name = old_name)`

For example, rename the `nr` to `id` since `nr` is the identifier of individual. `id` is a better name because it is more straightforward. 

```{r}
Males %>% 
  rename(id = nr)
```

`select()` can be used to rename a column too. However, it is rarely used because it drops all unselected columns, which is usually not desirable.  
```{r}
Males %>% 
  select(id = nr)
```

How can you use `select()` to obtain the exact result from `rename()`?
```{r}
Males %>% 
  select(id = nr, everything())
```



## mutate()
Sometimes it would be helpful to generate new features from existing columns. `mutate()` help you achieve this.

> `mutate()` generates new features from existing columns and append them to the end of the dataframe.

For example, in the `happy.df` dataset, one may be interested in the difference between two adjacent happiness score.
```{r}
happy.df %>% 
  mutate(score.diff = Score - lag(Score)) %>% 
  select(Score, score.diff)
```

Same as all dplyr functions, all changes are not made in-place.
```{r}
"score.df" %in% colnames(happy.df)
```

To preserve changes, remember to assign the returned dataframe to a new variable or even replace the original dataframe.
```{r}
delta.score.df <- 
  happy.df %>% 
  mutate(score.diff = Score - lag(Score)) %>% 
  select(Score, score.diff)
```

```{r}
str(delta.score.df)
```

If you ONLY want to keep the new variables, try `transmute()`
```{r}
happy.df %>% 
  transmute(score.diff = Score - lag(Score))
```

How to make `mutate()` produce the same results as `transmute()`?
```{r}
happy.df %>% 
  mutate(score.diff = Score - lag(Score)) %>% 
  select(score.diff)
```



### Creation Functions
Operations that can be used in `mutate()` or `transmute()`

1. Arithmetic operators: `+` `-` `*` `/` `^` 
1. Modular arithmetic: `%/%` (integer division) `%%`(remainder)
1. Logs: `log()` `log2()` `log10()`
1. Offsets: `lead()` and `lag()`
1. Cumulative and rolling aggregates: `cumsum()` `cumprod()` `cummin()` `cummax()` `cummean()`
1. Logical comparisons: `<` `<=` `>` `>=` `!=`
1. Ranking `min_rank()` `row_number()` `dense_rank()` `percent_rank()` `cume_dist()` `ntile()`

## summarize()
> `summarize()` most of the time works with `group_by()` to obtain group statistics.

```{r}
Males %>% 
  group_by(maried, health) %>% 
  summarize(mean.wage = mean(wage, na.rm=TRUE),
            count = n(),
            missing.count = sum(is.na(wage)))
```

Note that columns passed to `group_by()` should be categorical variables (Factor). Since both `maried` and `health` are binary (either has only 2 level - yes and no), there are in total 4 resultant groups. The statistics summarized by `summary()` is the statistics specific to each group.

### Summary Functions
1. measures of location `mean(x)` `median(x)`
1. measures of spread `sd(x)` `IQR(x)` `mad(x)`
1. measures of rank `min(x)` `quantile(x, 0.25)` `max(x)`
1. measures of position `first(x)` `nth(x, 2)` `last(x)`
1. counts `n()` `n_distinct(x)`
1. counts and proportions of logical values `sum(x > 10)` `mean(y == 0)`

> It is a good practice to pass `na.rm=TRUE` everytime one calls those summary functions, since every operation on `NA` yields `NA`, which typically jeopardizes analysis.  


### Ungrouping
> `ungroup()` removes grouping

```{r}
Males %>% 
  group_by(maried, health) %>% 
  ungroup() %>% 
  summarize(mean.wage = mean(wage, na.rm=TRUE),
            count = n(),
            missing.count = sum(is.na(wage)))
```
## Summary
Command Names | Tasks                                 
:------------:|:--------------------------------------
`filter`      | filtering rows by setting rules
`arrange`     | reordering rows
`select`      | selecting columns by names
`rename`      | renaming column names, and return all columns
`mutate`      | creating new variables with functions of existing columns
`transmute`   | creating new variables with functions of existing columns and returning only the new variables
`group_by`    | grouping factors
`ungroup`     | removing all groups
`summarize`   | obtaining statistical summary, such as mean, count, standard deviation, from selected data

# readr: Data Import and Output

Function Names | Tasks                                 
:-------------:|:--------------------------------------
`read_csv()`   | read comma-delimited files
`read_csv2()`  | read semicolon-separated files       
`read_tsv()`   | reads tab-delimited files
`read_delim()` | reads in files with any delimiter
`write_csv()`  | writes comma-delimited files to disk
`write_tsv()`  | writes tab-delimited files to disk

> The first argument to these functions are the path to the file to read.

## Under the Default Setting
```{r}
happy.df2 <- read_csv("../data/WorldHappiness2018_Data.csv")
```

The message output by `read_csv()` includes the name and type of each column.

> By default, `read_csv()` uses the first line of data for column names.

In the occasion that this is not the case, some additional arguments should be adjusted.

## Skip First Few Rows
```{r}
read_csv("This example is created
          to demonstrated how to use `skip`
          x, y, z
          1, 2, 3
          4, 5, 6", skip = 2)
```

## Skip Comments
```{r}
read_csv("# This example is created
          x, y, z  #column name
          1, 2, 3 
          4, 5, 6", comment = "#")
```

Please note that `read_csv()` does not ignore rows containing "#". Instead, it only neglects strings come after "#". In other words, warning will occur if there are only spaces preceeding "#".

## No Column Names
```{r}
read_csv("1,2,3\n4,5,6", col_names = FALSE)
```

If no column names are provided, R labels them sequentially from X1 to Xn. Alternatively, you can pass the column names as a vector.
```{r}
read_csv("1,2,3\n4,5,6", col_names = c("a", "b", "c"))
```

## Handle `NA` values
The missing value in R by default is spelt as `NA`. However, conventionally, null, NAN, NaN even some special symbols are used to represent missing values. To import whatever is supposed to be missing values as `NA` instead of strings, one needs to specify how the file to be imported represent missing values.

If left without handling, NaN, null will be treated as characters instead of missing values

```{r}
read_csv("a,b,c\n1,2,null\nNaN,5,6")
```

`na = "NaN"` tells R that the document uses `NaN` to represent missing values.
```{r}
read_csv("a,b,c\n1,2,null \nNaN,5,6", na = "NaN")
```

In this example, the document uses mixed notations to represent missing values. In this case, pass all missing value representations as a vector.
```{r}
read_csv("a,b,c\n1,2,.\nNaN,5,6", na = c(".", "NaN"))
```

## Write to a File
```R
write_csv(df, path)
```

`df` is a dataframe and path is the location you want the file saved at.


# stringr: Strings and Regular Expressions
## String Basics

> You can create a string with either single quotes or double quotes.

```{r}
single.quote <- 'a single quote string'
double.quote <- "a double quote sting"
```

> To include a literal single or double quote, you can either use \\ to escape it, or use single quotes and double quotes alternatively.

```{r}
lit.double.quote <- '"' # or "\""
lit.double.quote
```
```{r}
lit.single.quote <- '\'' # or "'"
lit.single.quote
```

Quiz. How to include a literal backslash `\`? 

## Special Characters
There are many special characters represented by strings. The most common are `\n`, for newline, and `\t` for tab.

```{r}
writeLines("First line\nSecond line\tA tab")
```

Unicode is mapping of string to special symbols. Those strings start with "\\u", followed by four-digit numbers or English letters. You can find the mapping table [here](https://unicode-table.com/en/).
```{r}
writeLines("\u2602")
```

## writeLines()
`writeLines` is the R equivalence of `print` function of Python. It is used to display the raw contents of the string. For example:
```{r}
lit.double.quote
```

```{r}
writeLines(lit.double.quote)
```

Without `writeLines`, `\n` and `\t` will not be interpreted.
```{r}
"First line\nSecond line\tA tab"
```

```{r}
writeLines("First line\nSecond line\tA tab")
```

## str_length()
The functions from `stringr` all start with `str_`. Starting from this subsections, I will introduce a few most commonly used string functions from `stringr`.

> `str_length()` tells you the number of characters in a string.

```{r}
str_length(c("happy", "sad", "calm"))
```

## str_c()

> `str_c()` combines two or more strings

```{r}
str_c("a", "b", "c")
```

> Arg 1: use `sep` to control how they are separated

```{r}
str_c("a", "b", "c", sep = ", ")
```


```{r}
writeLines(str_c("a", "b", "c", sep="\n"))
```

`str_c()` is vectorized, which means if a vector is passed to it, then `str_c()` is applied to each item in the vector.

```{r}
x <- c("Tom", "Jerry", "Sam", "Lucy")
str_c("Welcome to the class,", x, "!", sep = " ")
```

> Arg 2: To collapse a vector of strings into a single string, use `collapse`

```{r}
str_c(x, collapse = ", ")
```

## str_replace_na()

> `str_replace_na()` turn `NA` into "NA"

```{r}
x <- c("ab", "cd", NA, "gh")
str_replace_na(x)
```

## str_sub()
> `str_sub()` extract parts of a string. The template is `str_sub(string, start, end)`

```{r}
x <- c("Engineering", "Medicine", "Social Science", "Law", "Business")
str_sub(x, 1, 3)
```

Similar to Python, negative numbers count backwards from the end
```{r}
str_sub(x, -3, -1)
```

## str_to_lower()
> str_to_lower() changes all letters to lowercase.

```{r}
x <- c("Engineering", "Medicine", "Social Science", "Law", "Business")
str_to_lower(x)
```

Similarly, there is `str_to_upper()` and `str_to_title()`

```{r}
x <- str_to_upper(x)
x
```

```{r}
str_to_title("the university of hong kong")
```

## str_view()
In large datasets, it is likely that string-type columns carry important information. However, strings usually cannot be processed directly. A typical pipeline is to use regular expressions to identify different groups of strings with common patterns and encode them accordingly. `str_view()` and `str_view_all()` allow us to match strings by regular expressions. `str_vew()` shows the first match, while `str_view_all()` shows all the matches. 

### Exact Match

```{r}
x <- c("Engineering", "Medicine", "Science", "Social Science")
str_view(x, "ne")
```

### `.` to match any character except a newline
```{r}
str_view(x, ".e.")
```

### `^`  to match the start of the string
```{r}
str_view(x, "^Sci")
```


### `$` to match the end of the string
```{r}
str_view(x, "ing$")
```

### `\d` to match any digit
But remember you need to escape the "\\" for the string.
```{r}
x <- c("in the winter of 1993", "23 years old")
str_view(x, "\\d")
```

### `\s` to match any spaces
```{r}
str_view_all(x, "\\s")
```

### Alternatives

Expression|Meaning                      
:--------:|-----------------------------------
[abc]     | to match a, b, or c
[^abc]    | to match anything except a, b or c
app|tab   | to match either app or tab


### Repetition

Expression|Meaning                      
:--------:|-----------------------------------
?         | the pattern repeats 0 or 1 times
+         | the pattern repeats 1 or more times
*         | the pattern repeats 0 or more times 

```{r}
x <- c("Engineering", "Medicine", "Science", "Social Science")
str_view(x, "^S[a-zA-Z ]+ce$")
```

## str_detect()

> `str_detect()` returns a logical vector the same length as the input indicating if the patter appear.

```{r}
x <- c("Engineering", "Medicine", "Science", "Social Science")
str_detect(x, "e$")
```

A common use of `str_detect()` is to select elements that match a pattern. 
```{r}
x[str_detect(x, "e$")]
```

This is what to put in the `filter()` from `dplyr`.
```{r}
happy.df %>% 
  filter(str_detect(Country, "United"))
```

## str_extract()
> `str_extract()` extracts matching patterns from a string (what is highlighted in `str_view()`)

```{r}
x <- c("drop", "troop", "open", "close")
str_extract(x, "op$")
```

## str_replace()

> `str_replace()` allows you to replace the first match with new strings, while `str_replace_all()` replaces all matches with new strings.

```{r}
x <- c("apple", "pear", "banana")
str_replace(x, "[aeiou]", "-")
```

```{r}
str_replace_all(x, "[aeiou]", "-")
```

## str_split()

> str_split() splits a string up to pieces.

```{r}
str_split("The University of Hong Kong", " ")
```

# forcats: Working with Factors
`forcats` is a package for processing factors, or categorical variables. It is not part of the core tidyverse, so should be loaded explicitly.
```{r}
library(forcats)
```


## Creating Factors

> `factor(vec1, levels = vec2)` 


```{r}
month_levels <- c(
  "Jan", "Feb", "Mar", "Apr", "May", "Jun",
  "Jul", "Aug", "Sep", "Oct", "Nov", "Dec"
)

x <- c("Feb", "Jan", "Nov", "May")
y <- factor(x, levels = month_levels)
y
```

```{r}
sort(y)
```

```{r}
tshirt_size = c("XS", "S", "M", "L", "XL")
x <- c("S", "XS", "XL", "M", "M", "M", "L")
y = factor(x, levels = tshirt_size)
sort(y)
```

If you omit the levels, `sort` function will sort values alphabetically.

```{r}
Males %>% 
  count(ethn)
```

```{r}
ggplot(Males) + 
  geom_bar(aes(ethn))
```

## Modifying Factor Order

```{r}
Males %>% 
  group_by(industry) %>% 
  summarize(mean.wage = mean(wage)) %>% 
ggplot() +
  geom_point(aes(mean.wage, industry))
```

It is difficult to interpret this plot because there’s no overall pattern. We can improve it by reordering the levels of relig using `fct_reorder()`.


```{r}
Males %>% 
  group_by(industry) %>% 
  summarize(mean.wage = mean(wage)) %>% 
ggplot() +
  geom_point(aes(mean.wage, fct_reorder(industry, mean.wage)))
```

## Modifying Factor Levels
```{r}
levels(Males$industry)
```

```{r}
cleaned.males <- Males %>% 
  mutate(industry = fct_recode(industry,
         "Professional and Related Service" = "Professional_and_Related Service",
         "Business and Repair Service" = "Business_and_Repair_Service",
         "Personal Service" = "Personal_Service",
         "Public Administration" = "Public_Administration"))
```

```{r}
levels(cleaned.males$industry)
```

`fct_recode()` will leave levels that aren't explicitly mentioned as is, and will warn you if you accidentally refer to a level that doesn't exist.

To combine groups, you can assign multiple old levels to the same new level
```{r}
cleaned.combined.males <- cleaned.males %>% 
  mutate(industry = fct_recode(industry,
    "Service" = "Business and Repair Service",
    "Service" = "Professional and Related Service",
    "Service" = "Personal Service"))
levels(cleaned.combined.males$industry)
```

If you want to collapse a lot of levels, `fct_collapse()` is a useful variant of `fct_recode()`
```{r}
cleaned.concise.males <- cleaned.males %>% 
  mutate(industry = fct_collapse(industry,
    Service = c("Business and Repair Service",
                "Professional and Related Service",
                "Personal Service")))
levels(cleaned.concise.males$industry)
```





